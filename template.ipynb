{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Predictor\n",
    "\n",
    "**Name(s)**: Jawad Najar and Ali Boussi\n",
    "\n",
    "**Website Link**: (your website link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['gameid'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()\n",
    "\n",
    "# filter for complete data\n",
    "df = df[df['datacompleteness'] == 'complete']\n",
    "\n",
    "# drop unnecessary columns (metadata)\n",
    "meta_columns = ['participantid', 'playerid', 'teamid', \n",
    "                'datacompleteness', 'url', 'date',\n",
    "                'teamname', 'playername']\n",
    "df = df.drop(columns=meta_columns)\n",
    "\n",
    "# seperate team and player stats\n",
    "team_df = df[df['position'] == 'team']\n",
    "player_df = df[df['position'] != 'team']\n",
    "\n",
    "# Dropping all columnsn that are all NaN (it is a team/player stat, respectively)\n",
    "player_df = player_df.dropna(axis=1, how='all')\n",
    "team_df = team_df.dropna(axis=1, how='all')\n",
    "\n",
    "# Team Adv columns \n",
    "team_df['tower_advantage'] = team_df['towers'] - team_df['opp_towers']\n",
    "team_df['inhibitor_advantage'] = team_df['inhibitors'] - team_df['opp_inhibitors']\n",
    "team_df['gamelengthmin'] = team_df['gamelength'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data before imputation (if we decide to do it )\n",
    "# (only the winning games, otherwise the data will always be symmetric)\n",
    "\n",
    "# Visualize the distribution of gold difference columns\n",
    "gold_diff_columns = ['golddiffat10', 'golddiffat15', 'golddiffat20']\n",
    "for col in gold_diff_columns:\n",
    "    fig = px.histogram(\n",
    "        team_df[team_df['result'] == 1],\n",
    "        x=col,\n",
    "        nbins=20,\n",
    "        title=f'Distribution of {col}',\n",
    "        labels={col: 'Gold Difference'},\n",
    "        template='plotly_white',\n",
    "        color_discrete_sequence=['gold']\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        bargap=0.1,\n",
    "        xaxis_title='Gold Difference',\n",
    "        yaxis_title='Frequency',\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Visualize the distribution of XP difference columns\n",
    "xp_diff_columns = ['xpdiffat10', 'xpdiffat15', 'xpdiffat20']\n",
    "for col in xp_diff_columns:\n",
    "    fig = px.histogram(\n",
    "        team_df[team_df['result'] == 1],\n",
    "        x=col,\n",
    "        nbins=20,\n",
    "        title=f'Distribution of {col}',\n",
    "        labels={col: 'XP Difference'},\n",
    "        template='plotly_white',\n",
    "        color_discrete_sequence=['blue']\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        bargap=0.1,\n",
    "        xaxis_title='XP Difference',\n",
    "        yaxis_title='Frequency',\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding against imputation here, as NaN values represent that a game has ended prior to that time\n",
    "# and we want to keep that information\n",
    "\n",
    "# Creating 3 features that we will plot against one another in the future\n",
    "player_df['avg_xpdiff'] = player_df[xp_diff_columns].mean(axis=1, skipna=True)\n",
    "player_df['avg_golddiff'] = player_df[gold_diff_columns].mean(axis=1, skipna=True)\n",
    "player_df['game_length_min'] = player_df['gamelength'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    team_df,\n",
    "    x='tower_advantage',\n",
    "    nbins=15,  \n",
    "    title='Distribution of Tower Advantage',\n",
    "    labels={'tower_advantage': 'Tower Advantage (Team - Opponent)'},\n",
    "    color_discrete_sequence=['indianred'] \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    bargap=0.1, \n",
    "    template='plotly_white',  \n",
    "    xaxis_title='Tower Advantage',\n",
    "    yaxis_title='Number of Games',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    team_df,\n",
    "    x='inhibitor_advantage',\n",
    "    nbins=15, \n",
    "    title='Distribution of Inhibitor Advantage',\n",
    "    labels={'inhibitor_advantage': 'Inhibitor Advantage (Team - Opponent)'},\n",
    "    color_discrete_sequence=['skyblue'] \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    bargap=0.1, \n",
    "    template='plotly_white', \n",
    "    xaxis_title='Inhibitor Advantage',\n",
    "    yaxis_title='Number of Games',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy df\n",
    "gold_stats = team_df.copy()[['gameid', 'earnedgold', 'side', 'result']]\n",
    "\n",
    "gold_stats['red_win'] = ((gold_stats['result'] == 1) & ((gold_stats['side'] == 'Red')))\n",
    "red_side_gold = gold_stats.loc[gold_stats['side'] == 'Red', ['gameid', 'earnedgold', 'red_win']]\n",
    "blue_side_gold =  gold_stats.loc[gold_stats['side'] == 'Blue', ['gameid', 'earnedgold']]\n",
    "gold_final = red_side_gold.merge(blue_side_gold, on='gameid', suffixes=('_red', '_blue'))\n",
    "\n",
    "fig = px.scatter(\n",
    "    gold_final,\n",
    "    x='earnedgold_red',\n",
    "    y='earnedgold_blue',\n",
    "    color='red_win',\n",
    "    color_discrete_map={True: '#D2042D', False: '#0047AB'},\n",
    "    opacity=0.6,\n",
    "    hover_data={\n",
    "        'earnedgold_red': ':.0f',\n",
    "        'earnedgold_blue': ':.0f',\n",
    "        'red_win': True\n",
    "    },\n",
    "    labels={\n",
    "        'earnedgold_red': 'Red Team Gold',\n",
    "        'earnedgold_blue': 'Blue Team Gold',\n",
    "        'red_win': 'Red Team Won'\n",
    "    },\n",
    "    title='Red Gold Earned vs Blue Gold Earned by Game Outcome'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white', \n",
    "    xaxis=dict(title='Red Team Earned Gold', tickformat=',', title_font_size=16),\n",
    "    yaxis=dict(title='Blue Team Earned Gold', tickformat=',', title_font_size=16),\n",
    "    legend_title_text='Red Team Win?',\n",
    "    legend=dict(font=dict(size=12))\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we will sample 10% of the games\n",
    "wins = player_df[player_df['result'] == 1]\n",
    "all_games = wins['gameid'].drop_duplicates()\n",
    "sampled_games = all_games.sample(frac=0.1, random_state=98)\n",
    "sampled_df = wins[wins['gameid'].isin(sampled_games)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    sampled_df,\n",
    "    x='game_length_min',\n",
    "    y='avg_xpdiff',\n",
    "    color='position',\n",
    "    title='Game Length (minutes) vs Average XP Difference by position (Winning Games)',\n",
    "    labels={'avg_xpdiff': 'Average XP Difference', 'game_length_min': 'Game Length (minutes)'},\n",
    "    template='plotly_white',\n",
    "    hover_data=['position']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Game Length (minutes)',\n",
    "    yaxis_title='Average XP Difference',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    sampled_df,\n",
    "    x='game_length_min',\n",
    "    y='avg_golddiff',\n",
    "    color='position',\n",
    "    title='Game Length (minutes) vs Average Gold Difference by position (Winning Games)',\n",
    "    labels={'game_length_min': 'Game Length (minutes)', 'avg_golddiff': 'Average Gold Difference'},\n",
    "    template='plotly_white',\n",
    "    hover_data=['position']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Game Length (minutes)',\n",
    "    yaxis_title='Average Gold Difference',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of Gold and XP Difference with Win by Position\n",
    "gold_corr = player_df.groupby('position').apply(lambda g: g['avg_golddiff'].corr(g['result']))\n",
    "xp_corr = player_df.groupby('position').apply(lambda g: g['avg_xpdiff'].corr(g['result']))\n",
    "\n",
    "imp = (pd\n",
    "       .DataFrame({'gold': gold_corr, 'xp': xp_corr})\n",
    "       .reset_index()\n",
    "       .melt(id_vars='position', var_name='metric', value_name='corr'))\n",
    "\n",
    "fig = px.bar(\n",
    "    imp,\n",
    "    x='position',\n",
    "    y='corr',\n",
    "    color='metric',\n",
    "    barmode='group',\n",
    "    title='Correlation of Gold/XP Difference with Win by Position',\n",
    "    labels={'corr':'Correlation with Win','position':'Position','metric':'Metric'},\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.update_layout(font=dict(size=14))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_games = team_df.sample(frac=0.1, random_state=98)\n",
    "fig = px.scatter(\n",
    "    sampled_games,\n",
    "    x='totalgold',\n",
    "    y='gamelengthmin',\n",
    "    title='Total Gold vs Game Length (minutes)',\n",
    "    labels={'totalgold': 'Total Gold', 'gamelengthmin': 'Game Length (minutes)'},\n",
    "    template='plotly_white',\n",
    "    hover_data=['position']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Total Gold',\n",
    "    yaxis_title='Game Length (minutes)',\n",
    "    font=dict(size=14)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pivot table for win rates by champion and position\n",
    "# Example of how this reads: \"Aatrox has a win rate of .535 in the top lane, not played in any other lane\"\n",
    "win_rates = player_df.groupby(['champion','position'])['result'] \\\n",
    "                    .agg(win_rate='mean', games='count') \\\n",
    "                    .reset_index()\n",
    "\n",
    "pd.pivot_table(\n",
    "    win_rates[win_rates['games'] >= 30],\n",
    "    index='champion',\n",
    "    columns='position',\n",
    "    values='win_rate'\n",
    ").sort_values(by='champion', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> When a team is down by, say, >5k gold at 20â€¯minutes, predict the probability they still win. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'totalgold',\n",
    "    'earnedgold',\n",
    "    'minionkills',\n",
    "    'team kpm',\n",
    "    'ckpm',\n",
    "    'cspm',\n",
    "    'deaths',\n",
    "    'earned gpm',\n",
    "    'visionscore',\n",
    "    'monsterkills',\n",
    "    'damagetochampions',\n",
    "    'teamkills',\n",
    "    'vspm',\n",
    "    'wardsplaced',\n",
    "    'dpm',\n",
    "    'goldspent',\n",
    "    'wpm'\n",
    "]\n",
    "X = team_df[features]\n",
    "y = team_df['gamelength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, FunctionTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each feature and plot its distribution to see which are non-normal\n",
    "for feature in features:\n",
    "    fig = px.histogram(\n",
    "        team_df, \n",
    "        x=feature, \n",
    "        nbins=30, \n",
    "        title=f'Distribution of {feature}', \n",
    "        labels={feature: feature.capitalize()},\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title=feature.capitalize(),\n",
    "        yaxis_title='Frequency',\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns that we will end up using a Quantile Transformer on\n",
    "non_normal_features = [\n",
    "    \"team kpm\",         # Right-skewed\n",
    "    \"ckpm\",             # Right-skewed\n",
    "    \"deaths\",           # Left-skewed\n",
    "    \"earned gpm\",       # Bimodal\n",
    "    \"damagetochampions\",# Right-skewed\n",
    "    \"teamkills\"         # Left-skewed\n",
    "]\n",
    "\n",
    "col_trans = make_column_transformer(\n",
    "    (QuantileTransformer(output_distribution='normal'), non_normal_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "svr_pipeline = make_pipeline(\n",
    "    col_trans,\n",
    "    StandardScaler(),\n",
    "    Lasso(alpha=0.1, random_state=42),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.440e+09, tolerance: 5.121e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.863e+09, tolerance: 5.103e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.411e+09, tolerance: 5.118e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.299e+09, tolerance: 5.121e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.447e+09, tolerance: 5.103e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.174e+09, tolerance: 5.118e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e+09, tolerance: 5.114e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.809e+09, tolerance: 5.106e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.311e+09, tolerance: 5.106e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+09, tolerance: 5.114e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+10, tolerance: 5.121e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+10, tolerance: 5.121e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+10, tolerance: 5.106e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+10, tolerance: 5.114e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+10, tolerance: 5.118e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+10, tolerance: 5.103e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+10, tolerance: 5.103e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+10, tolerance: 5.118e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+10, tolerance: 5.114e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+10, tolerance: 5.106e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.790e+09, tolerance: 5.103e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.596e+09, tolerance: 5.118e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e+09, tolerance: 5.121e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.480e+09, tolerance: 5.121e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.433e+09, tolerance: 5.118e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.227e+09, tolerance: 5.114e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.728e+09, tolerance: 5.103e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e+09, tolerance: 5.106e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+09, tolerance: 5.114e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.739e+09, tolerance: 5.106e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+10, tolerance: 5.121e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+10, tolerance: 5.121e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e+10, tolerance: 5.103e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+10, tolerance: 5.118e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+10, tolerance: 5.106e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+10, tolerance: 5.114e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+10, tolerance: 5.103e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+10, tolerance: 5.118e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+10, tolerance: 5.114e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.021e+10, tolerance: 5.106e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+09, tolerance: 5.121e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e+09, tolerance: 5.103e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/boussi/miniforge3/envs/pds/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e+09, tolerance: 5.118e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"lasso__alpha\":      np.logspace(-3, 1, 20),\n",
    "    \"lasso__selection\":  [\"cyclic\", \"random\"],\n",
    "    \"lasso__fit_intercept\": [True, False],\n",
    "    \"lasso__max_iter\":   [10_000, 100_000],\n",
    "    \"lasso__tol\":        [1e-4, 1e-5],\n",
    "    \"lasso__positive\":   [False, True],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(svr_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best alpha:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05503596331011578\n",
      "              feature  coefficient\n",
      "6              deaths  1119.544629\n",
      "7          earned gpm  -843.063351\n",
      "8         visionscore     1.469283\n",
      "9        monsterkills    -0.878420\n",
      "10  damagetochampions     0.441720\n",
      "11          teamkills     0.441409\n",
      "4                ckpm     0.411317\n",
      "15          goldspent     0.314599\n",
      "14                dpm    -0.276253\n",
      "12               vspm    -0.248528\n",
      "1          earnedgold    -0.236624\n",
      "13        wardsplaced     0.205633\n",
      "2         minionkills     0.143612\n",
      "5                cspm     0.124889\n",
      "16                wpm    -0.114684\n",
      "3            team kpm    -0.053335\n",
      "0           totalgold    -0.030688\n"
     ]
    }
   ],
   "source": [
    "# Finding the most influential features\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "best_pipeline = grid.best_estimator_\n",
    "coefficients = best_pipeline.named_steps['lasso'].coef_\n",
    "intercept = best_pipeline.named_steps['lasso'].intercept_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "}).sort_values(by='coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coef_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
